{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d341e3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: iterative-stratification in c:\\users\\gusta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.1.9)\n",
      "Requirement already satisfied: numpy in c:\\users\\gusta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from iterative-stratification) (2.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\gusta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from iterative-stratification) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gusta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from iterative-stratification) (1.7.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\gusta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->iterative-stratification) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gusta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->iterative-stratification) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d09577c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['complex', 'frog_eye_leaf_spot', 'healthy', 'powdery_mildew', 'rust', 'scab'] (total=6)\n",
      "Total de imagens: 18632\n",
      "Tamanhos → train: 13063, val: 2773, test: 2796\n",
      "Found 13063 validated image filenames.\n",
      "Found 2773 validated image filenames.\n",
      "Found 2796 validated image filenames.\n",
      "Batch shapes → X: (32, 224, 224, 3) | y: (32, 6) | dtype y: float64\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Notebook 03 — Pré-processamento (Plant Pathology)\n",
    "# ===============================\n",
    "\n",
    "# 0) Imports\n",
    "import os, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 1) Caminhos e hiperparâmetros\n",
    "DATA_DIR   = Path(\"../data\")         # ajuste se necessário\n",
    "TRAIN_CSV  = DATA_DIR/\"train.csv\"\n",
    "TRAIN_DIR  = DATA_DIR/\"train_images\"\n",
    "TEST_DIR   = DATA_DIR/\"test_images\"  # (amostras; o teste real é oculto no Kaggle)\n",
    "\n",
    "IMG_SIZE   = (224, 224)  # bom ponto de partida p/ ResNet/EfficientNet\n",
    "BATCH_SIZE = 32\n",
    "SEED       = 42\n",
    "\n",
    "assert TRAIN_CSV.exists(), f\"train.csv não encontrado em {TRAIN_CSV}\"\n",
    "assert TRAIN_DIR.exists(), f\"train_images/ não encontrado em {TRAIN_DIR}\"\n",
    "\n",
    "# 2) Carregar labels e montar vetor multi-hot\n",
    "df = pd.read_csv(TRAIN_CSV)\n",
    "df.columns = [c.strip().lower() for c in df.columns]  # garante 'image' e 'labels'\n",
    "assert {\"image\", \"labels\"} <= set(df.columns), \"train.csv precisa conter colunas 'image' e 'labels'\"\n",
    "\n",
    "df[\"labels_list\"] = df[\"labels\"].astype(str).str.strip().str.split()\n",
    "all_labels = sorted({lab for labs in df[\"labels_list\"] for lab in labs})\n",
    "label2idx = {lab:i for i, lab in enumerate(all_labels)}\n",
    "\n",
    "def encode_multi_hot(labs):\n",
    "    v = np.zeros(len(all_labels), dtype=np.float32)\n",
    "    for lab in labs:\n",
    "        if lab in label2idx:\n",
    "            v[label2idx[lab]] = 1.0\n",
    "    return v\n",
    "\n",
    "df[\"y\"] = df[\"labels_list\"].apply(encode_multi_hot)\n",
    "Y = np.stack(df[\"y\"].values)\n",
    "\n",
    "print(\"Classes:\", all_labels, f\"(total={len(all_labels)})\")\n",
    "print(\"Total de imagens:\", len(df))\n",
    "\n",
    "# 3) Split treino/val/teste\n",
    "# ------------------------------------------------------------\n",
    "# Preferível: estratificação multi-label (Iterative Stratification).\n",
    "# Instale no Colab se quiser usar: !pip install iterative-stratification\n",
    "# Senão, caímos num fallback com estratificação aproximada pelo \"primeiro rótulo\".\n",
    "use_iterative = False\n",
    "try:\n",
    "    from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "    use_iterative = True\n",
    "except Exception as e:\n",
    "    use_iterative = False\n",
    "    print(\"Aviso: 'iterative-stratification' não disponível. Usando fallback de estratificação simples.\")\n",
    "\n",
    "df[\"primary_label\"] = df[\"labels_list\"].apply(lambda labs: labs[0] if len(labs)>0 else \"none\")\n",
    "\n",
    "if use_iterative:\n",
    "    # 70% train, 15% val, 15% test via duas passagens de stratified shuffle split\n",
    "    msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.30, random_state=SEED)\n",
    "    train_idx, temp_idx = next(msss.split(df[\"image\"], Y))\n",
    "    df_train = df.iloc[train_idx].reset_index(drop=True)\n",
    "    df_temp  = df.iloc[temp_idx].reset_index(drop=True)\n",
    "    Y_temp   = Y[temp_idx]\n",
    "\n",
    "    msss2 = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.50, random_state=SEED)\n",
    "    val_idx, test_idx = next(msss2.split(df_temp[\"image\"], Y_temp))\n",
    "    df_val  = df_temp.iloc[val_idx].reset_index(drop=True)\n",
    "    df_test = df_temp.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "else:\n",
    "    # Fallback: estratificar por rótulo primário (aproxima a distribuição)\n",
    "    df_train, df_temp = train_test_split(\n",
    "        df, test_size=0.30, random_state=SEED, stratify=df[\"primary_label\"]\n",
    "    )\n",
    "    df_val, df_test = train_test_split(\n",
    "        df_temp, test_size=0.50, random_state=SEED, stratify=df_temp[\"primary_label\"]\n",
    "    )\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_val   = df_val.reset_index(drop=True)\n",
    "    df_test  = df_test.reset_index(drop=True)\n",
    "\n",
    "print(f\"Tamanhos → train: {len(df_train)}, val: {len(df_val)}, test: {len(df_test)}\")\n",
    "\n",
    "# 4) Data augmentation (treino) e normalização (todas)\n",
    "# ------------------------------------------------------------\n",
    "# Observação: como é multi-label, vamos usar class_mode='raw' e passar Y (vetor multi-hot).\n",
    "train_aug = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.08,\n",
    "    height_shift_range=0.08,\n",
    "    zoom_range=0.12,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "\n",
    "valid_aug = ImageDataGenerator(rescale=1./255)\n",
    "test_aug  = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 5) Geradores Keras com y em formato 2D (uma coluna por classe)\n",
    "def make_df_for_flow(df_part, labels):\n",
    "    df_local = df_part[[\"image\"]].copy()\n",
    "    df_local[\"filepath\"] = df_local[\"image\"].apply(lambda n: str(TRAIN_DIR / n))\n",
    "    # cria colunas binárias y_<classe> = 0/1\n",
    "    for lab in labels:\n",
    "        df_local[f\"y_{lab}\"] = df_part[\"y\"].apply(lambda v: float(v[label2idx[lab]]))\n",
    "    return df_local\n",
    "\n",
    "label_cols = [f\"y_{lab}\" for lab in all_labels]\n",
    "\n",
    "df_train_flow = make_df_for_flow(df_train, all_labels)\n",
    "df_val_flow   = make_df_for_flow(df_val,   all_labels)\n",
    "df_test_flow  = make_df_for_flow(df_test,  all_labels)\n",
    "\n",
    "train_flow = train_aug.flow_from_dataframe(\n",
    "    dataframe=df_train_flow,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=label_cols,          # << várias colunas = matriz (batch, n_classes)\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"raw\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "val_flow = valid_aug.flow_from_dataframe(\n",
    "    dataframe=df_val_flow,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=label_cols,\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"raw\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_flow = test_aug.flow_from_dataframe(\n",
    "    dataframe=df_test_flow,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=label_cols,\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"raw\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "steps_train = int(np.ceil(len(df_train_flow) / BATCH_SIZE))\n",
    "steps_val   = int(np.ceil(len(df_val_flow)   / BATCH_SIZE))\n",
    "steps_test  = int(np.ceil(len(df_test_flow)  / BATCH_SIZE))\n",
    "\n",
    "xb, yb = next(iter(train_flow))\n",
    "print(\"Batch shapes → X:\", xb.shape, \"| y:\", yb.shape, \"| dtype y:\", yb.dtype)\n",
    "# esperado: y -> (32, 6) float32\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
